# Setup for Local LLM and GUI
`Note: This works only on MacOs systems and must have space on it.`
1. We first need to decide on the models we need based on our task
2. After finding the LLM, we head to huggingface or any AI marketplace we can find it.
3. We then decide on the language we you will use to build and communicate to the Model LLM

# Procedures to get the System Running
Head to Meta website and search for models
https://www.llama.com/llama-downloads

If you are approved, there would be a link shared with you to use for a custom download

3. Follow the procedure here and get it sorted out
4. https://github.com/meta-llama/llama-models?tab=readme-ov-file#download
After seting up the LLM locally, run the code below 
`pip install torch fairscale fire blobfile`
5. 